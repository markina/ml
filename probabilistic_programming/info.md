# Вероятностное программирование

### Примеры 

Mы хотим как-то рассуждать о процессах в реальном мире и о том, 
как эти процессы устроены.

Пример объекта:
* монетка 
* пользователь, который просматривает поисковую выдачу и решает, 
интересен ему поисковый результат или нет.

Пример свойств объекта:
* сиюминутные информационные потребности
* интересы в целом

Среда в который существуют эти объекты тоже обладает какими-то свойствами. 

Примеры сложного процесса:
* процесс подкидывания монетки 
* процесс просмотра пользователем поисковой выдачи

И, как правило, мы имеем какие-то наблюдаемые проявления этого процесса, 
хотим его обратить и понять, какими были свойства объектов и среды, 
которые привели к тому, что мы наблюдали. 

Например, посмотрев несколько раз на то, упала ли монетка орлом или решкой, 
мы хотим узнать честная монетка или нет. 

Или, посмотрев несколько раз на то, куда кликал пользователь, мы хотим понять, 
ушел ли он с поиска счастливым или несчастным, нашел он то, что нужно, или нет,
и были ли те документы, которые мы ему показали релевантными или нет. 

## Вероятностное моделирование
1. Упрощаем свойства объектов

Примеры:
* монетка описывается числом - честностью
* человек описывается вектором, каждое число показывает заинтересованность в 
какой-то области

2. Округление процесса

Примеры:
* пользователь просматривает выдачу сверху вниз,  если очередной результат 
удовлетворяет его информационной потребности, соотносится с его текущими 
интересами, то значит, он кликает и останавливается, а если нет, 
то идет дальше

3. Добавляем шум, чтобы приблизиться к реальности. 

Пример: 
* когда он видит очередной результат, он подкидывает монетку и в 
зависимости от того, как она выпала, решает, посмотреть ему этот результат, 
если он ему понравился, или пойти дальше, или устать и перестать смотреть 
выдачу

4. Обращение модели. Используем теорему Байеса: `P(A|B) = P(B|A)P(A)/P(B)`

## Вероятностное программирование

Основные принципы

1. Позволяет избежать написание кода вероятностного вывода, который очень сложный. 
2. Позволяет большому кругу людей пользоваться вероятностным моделированием. 

Идея

1. Описываем вероятностную модель
2. Генерируем наблюдаемые данные 
3. Добавляем шум 

## Примеры вероятностных программ 
    
### Пример

    // Model
    bool coin1Heads = Bernoulli.Sample(0.5);
    bool coin2Heads = Bernoulli.Sample(0.5);
    bool bothHeads = coin1Heads && coin2Heads;
    // Query
    observe bothHeads == false;
    infer coinHeads; // Bernoulli(0.333)
 
Семантика

* observe - проверяет, что ограничение выполняется, если не выполняется 
то исполнение прерывается
* infer - позволяет задавать вопросы. "сохраняет" текущее состояние переменных. 
и в какой-то момент, выдает с каким распределением получились переменные
    
### Пример True Skill

Есть результаты большого числа игр.
Хотим для любой пары игроков понять, с какой вероятностью 
первый выиграет второго, если они встретятся, даже 
если эти игроки никогда не играли между собой.

# Реализация 

### Результаты запусков 

Код будет немного преобразован в псевдокод. В классе Tests можно найти 
исходный код примеров.

#### Пример с честными монетками 

    d1 = flip(0.5) 
    d2 = flip(0.5)
    
    observe d1 || d2  
    infer d1        // {0=0.33, 1=0.67}
    infer d1        // {0=0.33, 1=0.67}

#### Пример с честной и нечестной монетками 

    d1 = flip(0.3) 
    d2 = flip(0.5)
    
    observe d1 || d2  
    infer d1        // {0=0.18, 1=0.82}
    infer d1        // {0=0.41, 1=0.59}
    
#### Пример с суммой
 
    d1 = flip(0.3) 
    d2 = multinomial({2: 0.1, 3: 0.3, 4: 0.6})
    
    observe d1 + d2 >= 4 
    infer d1        // {0=0.23, 1=0.77}
    infer d2        // {2=0.00, 3=0.26, 4=0.74}
    





 



  